{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "509e01c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from abc import ABC, abstractmethod\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import sys\n",
    "import math\n",
    "class SimpleTokenizer:\n",
    "    '''\n",
    "    Class to get the resources from the resource file\n",
    "    Variables\n",
    "    text -> which will contain the string from which we wnat to extract data\n",
    "    separator -> these are the separator which are use in resource file to separate the data\n",
    "    '''\n",
    "    start = -1\n",
    "    end = -1\n",
    "\n",
    "    def __init__(self, text, separators=[' ', '\\t', '\\n']):\n",
    "        self.text = text.replace('\\r\\n', '')\n",
    "        self.separators = separators\n",
    "        self.start = -1\n",
    "        self.end = -1\n",
    "\n",
    "    def hasToken(self):\n",
    "        self.start = self.end + 1\n",
    "        while (self.start < len(self.text) and self.isSeparator(self.text[self.start])):\n",
    "            self.start += 1\n",
    "        if (self.start < len(self.text)):\n",
    "            self.end = self.start - 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def nextInt(self):\n",
    "        while (self.start < len(self.text)):\n",
    "            try:\n",
    "                token = self.nextToken().strip()\n",
    "                return int(token)\n",
    "            except:\n",
    "                pass\n",
    "        raise Exception(\"NoSuchElement\")\n",
    "\n",
    "    def nextToken(self):\n",
    "        self.skipToken()\n",
    "        return self.text[self.start:self.end]\n",
    "\n",
    "    def skipToken(self):\n",
    "        self.start = self.end + 1\n",
    "        while (self.start < len(self.text) and self.isSeparator(self.text[self.start])):\n",
    "            self.start += 1\n",
    "        self.end = self.start + 1\n",
    "        while (self.end < len(self.text) and not self.isSeparator(self.text[self.end])):\n",
    "            self.end += 1\n",
    "\n",
    "    def isSeparator(self, character):\n",
    "        if character in self.separators:\n",
    "            return True\n",
    "        return False\n",
    "class Problem:\n",
    "    '''\n",
    "    Array Representation of the problem\n",
    "    Variables:\n",
    "    nJobs -> Number of Jobs\n",
    "    nMachines -> Number of Machines\n",
    "    processTimes -> Matrix with the process time of a job in a machine , processTimes[machine][job]\n",
    "    setupTimes -> Matrix with the setup times of the next job considering the current job on same machine\n",
    "    '''\n",
    "\n",
    "    def __init__(self, instancePath):\n",
    "        try:\n",
    "            print(os.getcwd()+'/'+instancePath)\n",
    "            with open(os.getcwd()+'/'+instancePath, 'r', newline='') as file:\n",
    "                self.token = SimpleTokenizer(file.readline())\n",
    "                self.nJobs = self.token.nextInt()\n",
    "                self.nMachines = self.token.nextInt()\n",
    "                # print('Jobs>>'+str(self.nJobs))\n",
    "                \n",
    "                self.processTimes = [[False for i in range(self.nJobs)] for j in range(self.nMachines)]\n",
    "                \n",
    "                self.setupTimes = [[[False for i in range(self.nJobs)] for j in range(self.nJobs)]for k in range(self.nMachines)]\n",
    "                file.readline()\n",
    "                for job in range(0, self.nJobs):\n",
    "                    self.token = SimpleTokenizer(file.readline())\n",
    "                    for machine in range(0, self.nMachines):\n",
    "                        machineid = self.token.nextInt()\n",
    "                        assert machine == machineid, \"machine doesnot match ID in file\"\n",
    "                        self.processTimes[machine][job] = self.token.nextInt()\n",
    "                file.readline()\n",
    "                for machine in range(0, self.nMachines):\n",
    "                    file.readline()\n",
    "                    for job in range(0, self.nJobs):\n",
    "                        self.token = SimpleTokenizer(file.readline())\n",
    "                        for nextJob in range(0, self.nJobs):\n",
    "                            self.setupTimes[machine][job][nextJob] = self.token.nextInt(\n",
    "                            )\n",
    "                            assert job != nextJob or self.setupTimes[machine][job][\n",
    "                                nextJob] == 0, \"setup between equal jobs must be zero\"\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    def __str__(self):\n",
    "        print('Array representation of Resource file')\n",
    "        print('Number of Jobs => ', self.nJobs)\n",
    "        print('Number of Machines => ', self.nMachines)\n",
    "        print('Process Time of Jobs => ', self.processTimes)\n",
    "        print('Setup Time of Jobs=>',self.setupTimes)\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dad524b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Particle:\n",
    "    def __init__(self, schedule):\n",
    "        self.schedule = schedule\n",
    "        self.fitness = calculate_fitness(schedule, processing_times, setup_times)\n",
    "#         self.velocity = [0 for _ in range(len(schedule))]\n",
    "        self.velocity = np.zeros((len(schedule), 2), dtype=np.int32)\n",
    "        self.best_schedule = self.schedule\n",
    "\n",
    "    def update_velocity(self, global_best):\n",
    "        w, c1, c2 = 0.8, 2, 2  # PSO parameters\n",
    "        for i in range(len(self.schedule)):\n",
    "            r1, r2 = random.random(), random.random()\n",
    "#             print(self.best_schedule)\n",
    "            cognitive = c1 * r1 * (self.best_schedule[i] - self.schedule[i])\n",
    "            social = c2 * r2 * (global_best[i] - self.schedule[i])\n",
    "            self.velocity[i] = w * self.velocity[i] + cognitive + social\n",
    "\n",
    "    def update_position(self):\n",
    "#         print('self.velocity',self.velocity)\n",
    "        for i in range(len(self.schedule)):\n",
    "            self.schedule[i] += (self.velocity[i])\n",
    "            if not (self.schedule[i][0]>=0 and self.schedule[i][0]<num_machines):\n",
    "                self.schedule[i][0] = random.randint(0, num_machines-1)\n",
    "        self.fitness = calculate_fitness(self.schedule, processing_times, setup_times)\n",
    "    def subtract_two_tuple(x,y):\n",
    "        return (x[0]-y[0],x[1]-y[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a87f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fitness(schedule, processing_times, setup_times):\n",
    "    # initialize the completion times of each job on each machine\n",
    "#     completion_times = [[0] * len(processing_times[0]) for _ in range(len(processing_times))]\n",
    "    completion_times = [[0] * problem.nMachines for _ in range(len(schedule))]\n",
    "    machine_done = []\n",
    "    machines = [[0] for _ in range(problem.nMachines)]\n",
    "#     print('sechd',schedule)\n",
    "    for k in schedule:\n",
    "        machines[k[0]] += [k[1]]\n",
    "    for i in range(len(machines)):\n",
    "        machines[i].pop(0)\n",
    "#     print('completion_times',completion_times)\n",
    "    # loop through each job in the schedule\n",
    "    for i in range(len(schedule)):\n",
    "        # get the machine and processing time for the job\n",
    "        machine = schedule[i][0]\n",
    "#         processing_time = processing_times[i][machine]\n",
    "        processing_time = processing_times[machine][i]\n",
    "        # calculate the start time of the job (maximum of completion time and setup time)\n",
    "#         start_time = max(completion_times[i][machine], setup_times[i][machine])\n",
    "        if machine not in machine_done:\n",
    "            start_time = completion_times[i][machine] + 0\n",
    "            machine_done.append(machine)\n",
    "#             start_time = max(completion_times[i][machine], setup_times[machine][i][i])\n",
    "        else:\n",
    "            l = machines[machine].index(schedule[i][1])\n",
    "            h = machines[machine][l-1]\n",
    "            start_time = completion_times[i][machine] + setup_times[machine][h][i]\n",
    "#             start_time = max(completion_times[i][machine],setup_times[machine][i-1][i])\n",
    "        # update the completion time of the job on the machine\n",
    "        completion_times[i][machine] = start_time + processing_time\n",
    "        # update the completion times of the remaining jobs on the machine\n",
    "        for j in range(i+1, len(schedule)):\n",
    "            if schedule[j][0] == machine:\n",
    "                completion_times[j][machine] = completion_times[i][machine]\n",
    "    # calculate the makespan (maximum completion time of all jobs on all machines)\n",
    "#     print('completion_times',completion_times)\n",
    "    makespan = max(max(completion_times[i]) for i in range(len(completion_times)))\n",
    "    # return the fitness (1/makespan, since we want to minimize makespan)\n",
    "    return 1/makespan\n",
    "\n",
    "# function to generate a random schedule\n",
    "def generate_schedule(num_jobs, num_machines):\n",
    "    schedule = np.zeros((num_jobs, 2), dtype=np.int32)\n",
    "#     schedule = []\n",
    "    \n",
    "    for i in range(num_jobs):\n",
    "        while True:\n",
    "            machine = random.randint(0, num_machines-1)\n",
    "#             cond = False\n",
    "            for k in schedule:\n",
    "                if k[0] == machine and k[1] == i:\n",
    "                    continue\n",
    "            break\n",
    "#         schedule.append([machine,i])\n",
    "        schedule[i][0]= machine\n",
    "        schedule[i][1] = i\n",
    "#     print('Schedule',schedule)\n",
    "    return schedule\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "005b2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def calculate_fitness(schedule, processing_times, setup_times):\n",
    "#     # function to calculate the fitness of a schedule\n",
    "#     # (same as given code)\n",
    "\n",
    "def generate_random_particle(num_jobs, num_machines):\n",
    "    schedule = generate_schedule(num_jobs, num_machines)\n",
    "    particle = Particle(schedule)\n",
    "    return particle\n",
    "\n",
    "def run_pso_algorithm(num_jobs, num_machines, processing_times, setup_times, population_size=100, num_generations=500):\n",
    "    # initialize the population\n",
    "    population = [generate_random_particle(num_jobs, num_machines) for _ in range(population_size)]\n",
    "    # set the global best particle\n",
    "    global_best = population[0].schedule\n",
    "    for particle in population:\n",
    "        if particle.fitness > calculate_fitness(global_best, processing_times, setup_times):\n",
    "            global_best = particle.schedule\n",
    "    # loop through each generation\n",
    "    for generation in range(num_generations):\n",
    "        # update the velocity and position of each particle\n",
    "        for particle in population:\n",
    "            particle.update_velocity(global_best)\n",
    "            particle.update_position()\n",
    "            # update the particle's best position\n",
    "            if particle.fitness > calculate_fitness(particle.best_schedule, processing_times, setup_times):\n",
    "                particle.best_schedule = particle.schedule\n",
    "            # update the global best position\n",
    "            if particle.fitness > calculate_fitness(global_best, processing_times, setup_times):\n",
    "                global_best = particle.schedule\n",
    "    return global_best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "529038e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\COdes\\Jupyter notebook\\Course\\Genetic Algorithm/resource.txt\n"
     ]
    }
   ],
   "source": [
    "inFile = \"resource.txt\"\n",
    "problem = Problem(inFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d67a564c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_jobs = problem.nJobs\n",
    "num_machines = problem.nMachines\n",
    "processing_times = problem.processTimes\n",
    "setup_times = problem.setupTimes\n",
    "# population_size = int(input(\"Enter the population size: \"))\n",
    "# no_of_generation = int(input(\"Enter the number of Generations: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ff0ab89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result Time 134.0\n",
      "Schedule0 [[ 3  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 3  3]\n",
      " [ 1  4]\n",
      " [ 3  5]\n",
      " [ 4  6]\n",
      " [ 1  7]\n",
      " [ 0  8]\n",
      " [ 2  9]\n",
      " [ 4 10]\n",
      " [ 0 11]]\n",
      "Wall time: 17.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "random.seed(0)\n",
    "result = run_pso_algorithm(num_jobs,num_machines,processing_times,setup_times)\n",
    "print(\"Result Time\",1/calculate_fitness(result,processing_times,setup_times))\n",
    "print('Schedule0',result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aeea1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
